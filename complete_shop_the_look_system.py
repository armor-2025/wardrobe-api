"""
Complete Shop the Look System
Celebrity Photo ‚Üí Visual Search ‚Üí Similar Products
"""
import os
import google.generativeai as genai
from PIL import Image
import clip
import torch
import json

os.environ['GEMINI_API_KEY'] = 'AIzaSyAgMKoVUg3IBhLKefBbxYPMf3VypicNzlU'
genai.configure(api_key=os.environ['GEMINI_API_KEY'])

print("=" * 70)
print("üõçÔ∏è  COMPLETE SHOP THE LOOK SYSTEM")
print("=" * 70)

class ShopTheLookEngine:
    def __init__(self):
        print("\nüîß Initializing...")
        
        # Load Gemini
        self.gemini = genai.GenerativeModel('gemini-2.5-flash-image')
        
        # Load CLIP
        self.device = "cpu"
        self.clip_model, self.clip_preprocess = clip.load("ViT-B/32", device=self.device)
        
        print("‚úÖ Ready!")
    
    def analyze_celebrity_photo(self, image_path):
        """
        Step 1: Gemini segments and identifies items
        """
        print(f"\nüì∏ Step 1: Analyzing {image_path.split('/')[-1]}...")
        
        image = Image.open(image_path)
        
        prompt = """Analyze this fashion photo and identify each clothing item.

For each item, provide:
1. Item type (blazer, dress, trousers, shoes, bag, sunglasses, jewelry, etc.)
2. Extremely detailed visual description for visual matching:
   - Exact color and shades
   - Material and texture
   - Style and cut
   - Special features (buttons, belts, pockets, etc.)
   - Pattern or finish
3. Approximate bounding box as percentages [x, y, width, height]

Return as JSON array:
[
  {
    "type": "blazer",
    "description": "emerald green oversized wool blazer with notched lapels",
    "bbox": [20, 15, 50, 45]
  }
]"""

        response = self.gemini.generate_content([prompt, image])
        
        # Parse JSON
        try:
            text = response.text
            if "```json" in text:
                text = text.split("```json")[1].split("```")[0]
            elif "```" in text:
                text = text.split("```")[1].split("```")[0]
            
            items = json.loads(text.strip())
        except:
            print("‚ö†Ô∏è  Could not parse JSON, using text")
            items = []
        
        print(f"‚úÖ Found {len(items)} items")
        for item in items:
            print(f"   - {item['type']}: {item.get('description', '')[:60]}...")
        
        return items, image
    
    def crop_item(self, image, bbox):
        """
        Step 2: Crop item from photo
        """
        width, height = image.size
        x = int(bbox[0] / 100 * width)
        y = int(bbox[1] / 100 * height)
        w = int(bbox[2] / 100 * width)
        h = int(bbox[3] / 100 * height)
        
        return image.crop((x, y, x + w, y + h))
    
    def generate_clip_embedding(self, image):
        """
        Step 3: Generate CLIP visual embedding
        """
        image_input = self.clip_preprocess(image).unsqueeze(0).to(self.device)
        
        with torch.no_grad():
            features = self.clip_model.encode_image(image_input)
            features = features / features.norm(dim=-1, keepdim=True)
        
        return features[0].cpu().numpy().tolist()
    
    def search_products(self, embedding, category, supabase_client, limit=20):
        """
        Step 4: Search database for similar products
        """
        result = supabase_client.rpc(
            'find_visually_similar_products',
            {
                'query_embedding': embedding,
                'filter_category': category,
                'match_count': limit
            }
        ).execute()
        
        return result.data
    
    def shop_the_look(self, celebrity_photo_path, supabase_client=None):
        """
        Complete workflow
        """
        print("\n" + "=" * 70)
        print("üõçÔ∏è  SHOP THE LOOK")
        print("=" * 70)
        
        # Step 1: Analyze
        items, original_image = self.analyze_celebrity_photo(celebrity_photo_path)
        
        results = []
        
        for i, item in enumerate(items):
            print(f"\nüîç Processing {item['type']}...")
            
            # Step 2: Crop (if bbox available)
            if 'bbox' in item and item['bbox']:
                cropped = self.crop_item(original_image, item['bbox'])
                cropped.save(f"cropped_{item['type']}_{i}.png")
                print(f"   ‚úÖ Cropped and saved")
            else:
                cropped = original_image
            
            # Step 3: Generate embedding
            embedding = self.generate_clip_embedding(cropped)
            print(f"   ‚úÖ Embedding generated ({len(embedding)} dims)")
            
            # Step 4: Search (if database connected)
            if supabase_client:
                products = self.search_products(
                    embedding=embedding,
                    category=item['type'] + 's',
                    supabase_client=supabase_client,
                    limit=20
                )
                print(f"   ‚úÖ Found {len(products)} similar products")
                
                results.append({
                    'item': item,
                    'embedding': embedding,
                    'products': products
                })
            else:
                results.append({
                    'item': item,
                    'embedding': embedding,
                    'products': []
                })
                print(f"   ‚ö†Ô∏è  No database - embedding ready for search")
        
        return results


# Demo
print("\n" + "=" * 70)
print("üß™ TESTING COMPLETE SYSTEM")
print("=" * 70)

engine = ShopTheLookEngine()

# Test with a celebrity photo
test_photo = os.path.expanduser('~/Desktop/AI OUTFIT PICS/IMG_6561.PNG')

results = engine.shop_the_look(test_photo, supabase_client=None)

print("\n" + "=" * 70)
print("‚úÖ COMPLETE SYSTEM WORKING!")
print("=" * 70)

print(f"\nüìä Results:")
for result in results:
    item = result['item']
    print(f"\n{item['type'].upper()}")
    print(f"  Description: {item.get('description', 'N/A')[:80]}...")
    print(f"  Embedding: {len(result['embedding'])} dimensions")
    print(f"  Ready for database search: ‚úÖ")

print("\n" + "=" * 70)
print("üéØ WHAT'S READY")
print("=" * 70)

print("""
‚úÖ Gemini analysis - segments items
‚úÖ CLIP embeddings - visual similarity
‚úÖ Complete workflow - end to end
‚¨ú Supabase database - need to set up
‚¨ú Product import - need to build
‚¨ú API endpoint - need to create

COST PER SEARCH:
- Gemini: $0.10
- CLIP: $0.00 (local)
- Total: $0.10

Next step: Set up Supabase database for products!
Want me to create the database setup script?
""")

