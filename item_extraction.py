"""
Smart Item Extraction from Outfit Photos
Upload one photo â†’ AI extracts multiple clothing items

Like ALTA app - segments outfit into individual items
"""
from sqlalchemy.orm import Session
from typing import List, Dict, Any, Optional
from PIL import Image
import io
import base64
import json


class ItemExtractor:
    """
    Extract individual clothing items from outfit photos
    Uses AI to detect, segment, and categorize items
    """
    
    def __init__(self):
        # TODO: Load actual AI models (YOLOv8, SAM, etc.)
        pass
    
    
    async def extract_items_from_photo(
        self,
        image_data: bytes,
        user_id: int
    ) -> Dict[str, Any]:
        """
        Main extraction pipeline
        
        Steps:
        1. Detect clothing items in image
        2. Segment each item (remove background)
        3. Classify category (top, bottom, shoes, etc.)
        4. Extract metadata (color, style)
        5. Return structured data for each item
        
        Args:
            image_data: Raw image bytes
            user_id: User who uploaded the photo
            
        Returns:
            {
                "original_photo": "base64_string",
                "items_detected": 4,
                "items": [
                    {
                        "item_id": "temp-001",
                        "category": "top",
                        "confidence": 0.95,
                        "bounding_box": [x1, y1, x2, y2],
                        "segmented_image": "base64_png",
                        "detected_attributes": {
                            "color": "black",
                            "style": "t-shirt",
                            "pattern": "solid"
                        }
                    }
                ]
            }
        """
        
        # For now, mock the extraction
        # In production, use actual AI models
        detected_items = await self._detect_items(image_data)
        
        results = {
            "original_photo": self._encode_image(image_data),
            "items_detected": len(detected_items),
            "items": []
        }
        
        for idx, item in enumerate(detected_items):
            # Segment item (remove background)
            segmented = await self._segment_item(image_data, item)
            
            # Classify category
            category = await self._classify_category(segmented)
            
            # Extract attributes
            attributes = await self._extract_attributes(segmented)
            
            results["items"].append({
                "item_id": f"temp-{idx+1:03d}",
                "category": category,
                "confidence": item.get("confidence", 0.9),
                "bounding_box": item.get("bbox", [0, 0, 100, 100]),
                "segmented_image": self._encode_image(segmented),
                "detected_attributes": attributes
            })
        
        return results
    
    
    async def _detect_items(self, image_data: bytes) -> List[Dict]:
        """
        Detect clothing items in image
        
        In production, use:
        - YOLOv8 for detection
        - Fashion-specific model (DeepFashion dataset)
        """
        # Mock detection - assume common outfit items
        return [
            {"bbox": [100, 50, 300, 200], "confidence": 0.95, "label": "top"},
            {"bbox": [100, 200, 300, 400], "confidence": 0.93, "label": "bottom"},
            {"bbox": [80, 400, 250, 500], "confidence": 0.91, "label": "shoes"},
            {"bbox": [300, 250, 350, 320], "confidence": 0.85, "label": "accessory"}
        ]
    
    
    async def _segment_item(
        self,
        image_data: bytes,
        detection: Dict
    ) -> bytes:
        """
        Segment item and remove background
        
        In production, use:
        - SAM (Segment Anything Model)
        - rembg for background removal
        - Create transparent PNG
        """
        # Mock - return original image
        # In production: crop to bbox, remove background
        return image_data
    
    
    async def _classify_category(self, image_data: bytes) -> str:
        """
        Classify clothing category
        
        Categories: top, bottom, dress, outerwear, shoes, accessories
        """
        # Mock classification
        import random
        categories = ["top", "bottom", "shoes", "outerwear", "accessories"]
        return random.choice(categories)
    
    
    async def _extract_attributes(self, image_data: bytes) -> Dict[str, str]:
        """
        Extract visual attributes
        
        Attributes:
        - Color (dominant color)
        - Style (casual, formal, sporty)
        - Pattern (solid, striped, floral)
        - Material (denim, cotton, leather - if detectable)
        """
        # Mock attributes
        return {
            "color": "black",
            "style": "casual",
            "pattern": "solid",
            "fit": "regular"
        }
    
    
    def _encode_image(self, image_data: bytes) -> str:
        """Convert image bytes to base64 string"""
        return base64.b64encode(image_data).decode('utf-8')
    
    
    def _decode_image(self, base64_string: str) -> bytes:
        """Convert base64 string to image bytes"""
        return base64.b64decode(base64_string)


# Helper functions for wardrobe integration
def create_wardrobe_items_from_extraction(
    db: Session,
    user_id: int,
    extraction_results: Dict[str, Any]
) -> List[int]:
    """
    Create wardrobe items from extracted items
    
    Returns list of created item IDs
    """
    from interaction_models import UserInteraction
    
    created_ids = []
    
    for item in extraction_results["items"]:
        # In production, save to actual wardrobe table
        # For now, create interaction to track the upload
        
        interaction = UserInteraction(
            user_id=user_id,
            action_type="wardrobe_add",
            item_id=item["item_id"],
            item_type="product",
            weight=15.0,  # High weight for items user owns
            interaction_metadata={
                "category": item["category"],
                "attributes": item["detected_attributes"],
                "source": "outfit_photo_extraction",
                "segmented_image": item["segmented_image"][:100]  # Store reference
            }
        )
        db.add(interaction)
        created_ids.append(item["item_id"])
    
    db.commit()
    return created_ids
